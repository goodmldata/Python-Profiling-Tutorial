{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c42f4a3f-9ef3-4b51-a033-c3bd470700c2",
   "metadata": {},
   "source": [
    "# 1. Code Profiling in Python: Introduction\n",
    "\n",
    "**Profiling** is a technique that allows us to pinpoint the most resource intensive parts of an application. It allows to search for bottlenecks in the code in a rigorous and systematic way.\n",
    "\n",
    "**Profiler** is a program that runs an application and monitors functions execution time, thus detecting the function on which the application spends the most of its time.\n",
    "\n",
    "**Benchmarks** are small scripts used to assess the total execution time of an application.\n",
    "\n",
    "We will learn how to run benchmarks and measure performance of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e558371b-b71b-457f-9e33-e6284eafaadb",
   "metadata": {},
   "source": [
    "## 1.1 Application Optimization Principles\n",
    "\n",
    "- Make it run!\n",
    "- Make it right!\n",
    "- Make it fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6426b34-950c-4e31-8caa-24ec831972fc",
   "metadata": {},
   "source": [
    "## 1.2 Particle Simulator\n",
    "\n",
    "A Particle Simulator is an application that was created  to showcase the benchmarking techniques.\n",
    "\n",
    "The Particle Simulator application simulates a scientific performance-intensive system. The application is capable to simulate the rotation of multiple particles over a central point. The particles angular rotation speed is constant. Each particle starts rotating from some predefined position, identified by the coordinates x and y. The users of the simulator want to be able to identify the position of any particle at any point of time.\n",
    "\n",
    "The code of the particle simulator is located in the project directory called **simulator**.\n",
    "\n",
    "The particle simulator code is very simple, it contains two classes\n",
    "\n",
    "1) Particle class, describing the particle. Each particle is characterized by the coordinates x and y, the angular velocity, and the color. \n",
    "2) ParticleSimulator class monitors the movement of the attached particles. It has the method called **.evolve()** that evaluates the position of every attached particle after time **dt**.\n",
    "\n",
    "#### Running Particle Simulator Visualization Code\n",
    " \n",
    "The Particle Simulator app contains a simple particle simulator visualization, it is located in the main.py file, and you can from the command line as follows:\n",
    "\n",
    "```\n",
    "$ python main.py\n",
    "```\n",
    "\n",
    "In order to see visualization on the screen, you havet to install **matplotlib** UI backend with the corresponding Python module.\n",
    "On my Linux system I have qt5 installed, and in addition I needed to install a Python module PyQT5. I'm not adding this as a dependency,\n",
    "because it is pretty much system dependent, and one needs to figure out what works best on his/her machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9356c4bd-5e7d-4c29-ba8d-ca980a79c666",
   "metadata": {},
   "source": [
    "## 1.3 Project Structure\n",
    "\n",
    "```\n",
    ".\n",
    "├── benchmarks\n",
    "│   ├── benchmark.py\n",
    "│   └── __init__.py\n",
    "├── main.py\n",
    "├── simulator\n",
    "│   ├── __init__.py\n",
    "│   └── particle_simulator.py\n",
    "├── tests\n",
    "│   ├── __init__.py\n",
    "│   └── test_particle_simulator.py\n",
    "└── Profiling_in_Python.ipynb\n",
    "```\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "- The file benchamrks/benchmark.py contains benchmark scripts.\n",
    "- The file simulator/particle_simulator.py contains particle simulator code.\n",
    "- The directory tests contains unit tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acade42a-3e7a-48b8-9887-692d385d9cc7",
   "metadata": {},
   "source": [
    "## 1.4 Code Profiling Tools We are Going to Learn\n",
    "\n",
    "1) Unix **time** command\n",
    "2) Python module **timeit**\n",
    "3) Pytest plugin **pytest-benchmark**\n",
    "4) Python module **cProfile**, and graphical tools used to visualize **cProfile** data\n",
    "5) Python third party library **line_profiler**\n",
    "6) Python third party library **memory_profiler**\n",
    "7) Python disassembly module **dis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b169dc3a-1fa5-41e1-ad90-68296bc4659e",
   "metadata": {},
   "source": [
    "## 1.5 Code Profiling Basics with **time** and **timeit**\n",
    "\n",
    "In this section we will learn the code profiling ABC with Unix command **time** and Python module **timeit**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bf4b2-f18f-4880-90e0-1fa715d3b4d1",
   "metadata": {},
   "source": [
    "### 1.5.1 Unix **time** command\n",
    "\n",
    "There is a project file **benchmark/benchmark.py**, it contains a benchmark code that we want to run and measure the run time. \n",
    "I will show how we can do it with the Unix **time** command. The command needs to be run from the Unix command line:\n",
    "\n",
    "\n",
    "```\n",
    "$  time python -m benchmarks.benchmark\n",
    "```\n",
    "\n",
    "That is what I'm getting back:\n",
    "\n",
    "```\n",
    "real    0m0,096s\n",
    "user    0m0,088s\n",
    "sys     0m0,008s\n",
    "```\n",
    "\n",
    "Please note that your results may be different, because they depend on your computer configuration.\n",
    "\n",
    "The interpretation of the results is as follows:\n",
    "\n",
    "**real**: The actual time spent running the process from start to finish.\n",
    "\n",
    "**user**: The cumulative time spent by all the central processing units (CPUs) during the direct computations.\n",
    "\n",
    "**sys**: The cumulative time spent by all the CPUs during system-related tasks, such as memory allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802f1c6-ad1d-45e9-8e49-19082ff60f05",
   "metadata": {},
   "source": [
    "### 1.5.2 Python **timeit** module\n",
    "\n",
    "**timeit** module is used to measure the execution time of small snippents of Python code.\n",
    "\n",
    "The **timeit** runs the snippet of code in a loop for *n* times and measures the execution time of n loops, then it repeats the same operation *r* times, then it chooses the quickest series of n loops, and calculates the average loop runtime.\n",
    "\n",
    "I will set *n* to 100 and *r* to 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff3574-c89d-4045-a325-3bff8375f222",
   "metadata": {},
   "source": [
    "It is possible to use timeit from the command line, from the Jupyter Notebook (IPython), or as a part of the Python code. I will explain and demonstrate all the methods measuring the run time of the function called **run_benchmark()**. This function creates creates a ParticleSimulator object with one hundred Particle objects, and then moves the particles using the .evolve() method, the evolution time step is equal to 0.1.\n",
    "\n",
    "Please note that the best option is to run the timeit from the command line, the execution from the command line is a whole way faster than the execution from the Jupyter Notebook. \n",
    "\n",
    "#### Example 1: Using **timeit** from the command line\n",
    "\n",
    "```\n",
    "$ python -m timeit -s \"from benchmarks.benchmark import run_benchmark\" -n 100 -r 3 \n",
    "```\n",
    "\n",
    "On my machine I got the following result:\n",
    "\n",
    "```\n",
    "100 loops, best of 3: 7.22 nsec per loop\n",
    "```\n",
    "\n",
    "Essentially the the **timeit** command runs the function 100 times and measures the runtime of all 100 runtimes, then it repeats the process 3 times. The best (the quickest) series of 100 runs is chosen, and based on this series, the average function runtime is evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a56e0-66db-40f8-84c5-ca3d16d5aadf",
   "metadata": {},
   "source": [
    "#### Example 2: Using **timeit** from Jupyter Notebook (IPython environment)\n",
    "\n",
    "IPython is a Python shell that improves the interactivity of Python interpreter. IPython accepts *magic commands* - the statements that start with % symbol. The **timeit** can be invoked as a magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "052ef8bb-2530-427d-b48b-db82ec4b16ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.2 ms ± 1.72 ms per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Timing the run_benchmark() execution time using timeit and IPython magic commands\n",
    "\n",
    "from benchmarks.benchmark import run_benchmark\n",
    "\n",
    "%timeit -n 100 -r 3 run_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13884e21-3673-476d-964c-5bd22cfe2d86",
   "metadata": {},
   "source": [
    "#### Example 3: Using **timeit** from the Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabb5df0-5940-4e8e-b52b-dc400836532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      " [3.858473136000157, 3.7227985810000064, 3.553068225000061]\n"
     ]
    }
   ],
   "source": [
    "# Timing the run_benchmark() using timeit and Python\n",
    "\n",
    "import timeit\n",
    "\n",
    "n = 100\n",
    "r = 3\n",
    "\n",
    "result = timeit.repeat(\"run_benchmark()\", setup=\"from benchmarks.benchmark import run_benchmark\", number=n, repeat=r)\n",
    "\n",
    "print(\"Result:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487e4d9-6c7a-4308-ab95-6a213fd3231b",
   "metadata": {},
   "source": [
    "The results received from the Python code are in a slightly different form, but they are still comparable to the results received using the magic command in the **Example 2**. (In both cases the code was executed from the same environment - the Jupyter Notebook.)\n",
    "\n",
    "The result shows execution time of three series of 100 loops. Let's derive the average loop runtime, the way the **timeit** does it.\n",
    "In order to do so, we need to select the best series of 100 loops, and then we have to calculate the average loop runtime dividing the time by the number of loops in the series. \n",
    "\n",
    "#### Please pay attention how much faster was the execution when running the timeit from the command line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ea014-2cdd-4e40-a454-4328b6eb4fa0",
   "metadata": {},
   "source": [
    "#### Check the calculations and compare the results with the results received in the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1422f32a-1222-42c3-9d89-9dec421fabf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function average runtime: 35.53068225000061 ms.\n"
     ]
    }
   ],
   "source": [
    "# Single loop execution time\n",
    "\n",
    "function_avg_runtime = min(result) / n\n",
    "print(f\"Function average runtime: {function_avg_runtime * 1000} ms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44afca7-7d68-4eee-8578-1ce4d447e2df",
   "metadata": {},
   "source": [
    "## Exercise 1: Practice\n",
    "\n",
    "Re-run the **Example 1**, the **Example 2**, and the **Example 3** on your own machine, and update the notebook on your machine with your own results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9780c45-89ae-493c-a192-e1dea96519a7",
   "metadata": {},
   "source": [
    "## Exercise 2: Python Lists\n",
    "\n",
    "In theory Python lists shine in accessing, modifying, and appending elements, the complexity of these operations is *O(1)*. The operations, that add or remove elements at the beginning, or somewhere in the middle have the complexity *O(N)*. \n",
    "\n",
    "Create a list of 5000, 10000, and 20000 elements, and check if the theoretical statement holds in practice.\n",
    "\n",
    "a) Remove an element at the beginning, at the middle, and at the end of the list, compare the time of removing the element from the end, from the middle, and from the beginning of the list. Use list.pop() method. \n",
    "\n",
    "b) Append an element at the beginning, at the middle, and at the end of the list, compare the time of adding the element at the end, at the middle, and at the beginning of the list. Use list.append() to add the element at end of the list, and list.insert() to add the element at the beginning or in the middle of the list.\n",
    "\n",
    "c) Save the results to the summary table. Table columns:\n",
    "- Operation (operation name);\n",
    "- Operatation complexity (O(N) for example)\n",
    "- T5000 (the time the operation took on list with 5000 elements);\n",
    "- T10000\n",
    "- T20000\n",
    "\n",
    "d) Do you agree with the theoretical statements? Please explain your opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e94eef86-be0a-416c-bc70-5158bf289d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operation</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>T5000</th>\n",
       "      <th>T10000</th>\n",
       "      <th>T20000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>list.pop()</td>\n",
       "      <td>O(1)</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>list.pop(0)</td>\n",
       "      <td>O(N)</td>\n",
       "      <td>0.745</td>\n",
       "      <td>1.364</td>\n",
       "      <td>3.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>list.pop(N//2)</td>\n",
       "      <td>O(N)</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.793</td>\n",
       "      <td>1.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>list.append(1)</td>\n",
       "      <td>O(1)</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>list.insert(0, 1)</td>\n",
       "      <td>O(N)</td>\n",
       "      <td>1.381</td>\n",
       "      <td>2.555</td>\n",
       "      <td>4.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>list.insert(0, 1)</td>\n",
       "      <td>O(N)</td>\n",
       "      <td>0.822</td>\n",
       "      <td>1.431</td>\n",
       "      <td>2.595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Operation Complexity  T5000  T10000  T20000\n",
       "0         list.pop()       O(1)  0.165   0.176   0.174\n",
       "1        list.pop(0)       O(N)  0.745   1.364   3.321\n",
       "2     list.pop(N//2)       O(N)  0.515   0.793   1.479\n",
       "3     list.append(1)       O(1)  0.201   0.215   0.200\n",
       "4  list.insert(0, 1)       O(N)  1.381   2.555   4.860\n",
       "5  list.insert(0, 1)       O(N)  0.822   1.431   2.595"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Solution to Exercise 2\n",
    "\n",
    "import pandas as pd\n",
    "import timeit\n",
    "from random import randint, seed\n",
    "\n",
    "N = 1\n",
    "R = 10000\n",
    "summary = pd.DataFrame(columns=[\"Operation\", \"Complexity\", \"T5000\", \"T10000\", \"T20000\"])\n",
    "\n",
    "# Operation list.pop()\n",
    "op_name = \"list.pop()\"\n",
    "op_complexity = \"O(1)\"\n",
    "t5000 = min(timeit.repeat(\"arr.pop()\", setup = \"LS=5000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t10000 = min(timeit.repeat(\"arr.pop()\", setup = \"LS=10000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t20000 = min(timeit.repeat(\"arr.pop()\", setup = \"LS=20000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "\n",
    "summary.loc[len(summary.index)] = [op_name, op_complexity, t5000, t10000, t20000]\n",
    "\n",
    "\n",
    "# Operation list.pop(0)\n",
    "op_name = \"list.pop(0)\"\n",
    "op_complexity = \"O(N)\"\n",
    "t5000 = min(timeit.repeat(\"arr.pop(0)\", setup = \"LS=5000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t10000 = min(timeit.repeat(\"arr.pop(0)\", setup = \"LS=10000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t20000 = min(timeit.repeat(\"arr.pop(0)\", setup = \"LS=20000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "\n",
    "summary.loc[len(summary.index)] = [op_name, op_complexity, t5000, t10000, t20000]\n",
    "\n",
    "\n",
    "# Operation list.pop(N//2)\n",
    "op_name = \"list.pop(N//2)\"\n",
    "op_complexity = \"O(N)\"\n",
    "t5000 = min(timeit.repeat(\"arr.pop(LS//2)\", setup = \"LS=5000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t10000 = min(timeit.repeat(\"arr.pop(LS//2)\", setup = \"LS=10000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t20000 = min(timeit.repeat(\"arr.pop(LS//2)\", setup = \"LS=20000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "\n",
    "summary.loc[len(summary.index)] = [op_name, op_complexity, t5000, t10000, t20000]\n",
    "\n",
    "\n",
    "# Operation list.append()\n",
    "op_name = \"list.append(1)\"\n",
    "op_complexity = \"O(1)\"\n",
    "t5000 = min(timeit.repeat(\"arr.append(1)\", setup = \"LS=5000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t10000 = min(timeit.repeat(\"arr.append(1)\", setup = \"LS=10000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t20000 = min(timeit.repeat(\"arr.append(1)\", setup = \"LS=20000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "\n",
    "summary.loc[len(summary.index)] = [op_name, op_complexity, t5000, t10000, t20000]\n",
    "\n",
    "\n",
    "# Operation list.insert(0, 1)\n",
    "op_name = \"list.insert(0, 1)\"\n",
    "op_complexity = \"O(N)\"\n",
    "t5000 = min(timeit.repeat(\"arr.insert(0, 1)\", setup = \"LS=5000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t10000 = min(timeit.repeat(\"arr.insert(0, 1)\", setup = \"LS=10000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t20000 = min(timeit.repeat(\"arr.insert(0, 1)\", setup = \"LS=20000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "\n",
    "summary.loc[len(summary.index)] = [op_name, op_complexity, t5000, t10000, t20000]\n",
    "\n",
    "# Operation list.insert(N//2, 1)\n",
    "op_name = \"list.insert(0, 1)\"\n",
    "op_complexity = \"O(N)\"\n",
    "t5000 = min(timeit.repeat(\"arr.insert(LS//2, 1)\", setup = \"LS=5000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t10000 = min(timeit.repeat(\"arr.insert(LS//2, 1)\", setup = \"LS=10000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "t20000 = min(timeit.repeat(\"arr.insert(LS//2, 1)\", setup = \"LS=20000; arr=list(range(LS))\", number=N, repeat=R)) * 10**6\n",
    "\n",
    "summary.loc[len(summary.index)] = [op_name, op_complexity, t5000, t10000, t20000]\n",
    "\n",
    "\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb337cf5-8eda-4fba-8656-17edb8bb6f1d",
   "metadata": {},
   "source": [
    "## Exercise 2: Explaining Experiment Results\n",
    "\n",
    "The experiment results confirm the theoretical statement. How can we see that? First, let's formulate our expectations. \n",
    "\n",
    "- If the operation complexity is O(1) we expect that the results for different list sizes will be more or less similar. Of course processing of big lists will take longer that of the small ones, but this difference is not going to be significant.\n",
    "\n",
    "- If the complexity of the operation is O(N), then we expect that the processing of list of size 2*n will takes twice as long as processing of the list of size n.\n",
    "\n",
    "Now, let's look at the results. \n",
    "\n",
    "We can see that the time of the operations of complexity O(1) is roughly similar, there might be a small increase it operation execution time, when the list size grows but it is significantly slower than the growth rate of the size of the list.\n",
    "\n",
    "The time of the operations of complexity O(N) increases with the size of the list, and the increase in operation time is comparable to the increase in the size of the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96255a89-3bec-452e-bb97-61083f8c78aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
